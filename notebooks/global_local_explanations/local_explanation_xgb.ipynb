{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "c4449f22",
   "metadata": {},
   "source": [
    "JELIA CONFERENCE 2023 paper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9f33ec67",
   "metadata": {},
   "outputs": [],
   "source": [
    "# required modules (under Anaconda use: > conda install -c conda-forge <package>)\n",
    "if False: # (skip if already installed)\n",
    "    !pip install lark-parser\n",
    "    !pip install linear-tree\n",
    "    !pip install pydot\n",
    "    !pip install pydotplus\n",
    "    # download and install SWI Prolog from https://www.swi-prolog.org/download/stable\n",
    "    # be sure that the executable is added to the PATH"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b872578e",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%matplotlib inline\n",
    "\n",
    "# standard imports\n",
    "import sys\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "import pickle\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn import tree\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import RidgeClassifier\n",
    "import matplotlib.pyplot as plt\n",
    "import pydotplus\n",
    "from IPython.display import Image\n",
    "\n",
    "# imported packages\n",
    "from lineartree import LinearTreeClassifier\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "\n",
    "# local imports\n",
    "sys.path.append('../src/') # local path\n",
    "import reasonx\n",
    "import dautils"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "fca13807",
   "metadata": {},
   "source": [
    "### Example on continuous only attributes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb227f77",
   "metadata": {},
   "outputs": [],
   "source": [
    "continuous_only = False"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7d3d62b7",
   "metadata": {},
   "source": [
    "### Read dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02035481",
   "metadata": {},
   "outputs": [],
   "source": [
    "# read dataset\n",
    "df = pd.read_csv('../data/adult_continuous.csv', na_values='?')\n",
    "# remove unused columns\n",
    "del df['fnlwgt']\n",
    "del df['education-num']\n",
    "# simplify dataframe\n",
    "del df['marital-status']\n",
    "del df['native-country']\n",
    "del df['occupation']\n",
    "del df['relationship']\n",
    "# remove special characters in column names and values\n",
    "df.columns = df.columns.str.replace(\"[-&()]\", \"\", regex=True)\n",
    "df = df.replace('[-&()]', '', regex=True)\n",
    "# missing values imputation with mode (needed for Decision Trees)\n",
    "df = df.apply(lambda x:x.fillna(x.value_counts().index[0]))\n",
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "897dfaa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# nominal-ordinal-continuous partition of predictive attributes\n",
    "nominal_atts = [] if continuous_only else ['race', 'sex', 'workclass']\n",
    "ordinal_atts = [] if continuous_only else ['education']\n",
    "continuous_atts = ['age', 'capitalgain', 'hoursperweek'] if continuous_only else ['age', 'capitalgain', 'capitalloss', 'hoursperweek']\n",
    "# class attribute\n",
    "target = 'class'\n",
    "# predictive atts\n",
    "pred_atts = nominal_atts + ordinal_atts + continuous_atts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ad45a86",
   "metadata": {},
   "outputs": [],
   "source": [
    "# forcing encoding of ordinal attributes (consistent with the order) and class attribute (0=negatives, 1=positives)\n",
    "decode = {\n",
    "    'education': {\n",
    "        1:'Preschool', 2:'1st4th', 3:'5th6th', 4:'7th8th', 5:'9th', 6:'10th', 7:'11th',\n",
    "        8:'12th', 9:'HSgrad', 10:'Somecollege', 11:'Assocvoc', 12:'Assocacdm', 13:'Bachelors', \n",
    "        14:'Masters', 15:'Profschool', 16:'Doctorate' \n",
    "    },\n",
    "    'class': {\n",
    "        0: '<=50K', 1: '>50K'\n",
    "    }\n",
    "}\n",
    "# encode nominal (as categories), ordinal+target (as int), passing the encoding of ordinal+target\n",
    "prefix_sep = \"_\" # separator for one-hot encoding\n",
    "df_code = dautils.Encode(nominal=nominal_atts, ordinal=ordinal_atts+[target], decode=decode, onehot=True, prefix_sep=prefix_sep)\n",
    "df_encoded_onehot = df_code.fit_transform(df)\n",
    "df_encoded_onehot.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "875d964e",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# encode-decoding dictionaries\n",
    "df_code.encode, df_code.decode"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b11a8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "# encoded atts names\n",
    "encoded_pred_atts = df_code.encoded_atts(pred_atts)\n",
    "# split predictive and target\n",
    "X, y = df_encoded_onehot[encoded_pred_atts], df_encoded_onehot[target]\n",
    "X1, _, y1, _ = train_test_split(X, y, test_size=0.3, random_state=42)\n",
    "X2, _, y2, _ = train_test_split(X, y, test_size=0.3, random_state=24)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "729b357c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDED\n",
    "\n",
    "# pick data instance\n",
    "\n",
    "features=X1.iloc[0:1]\n",
    "label=y1.iloc[0]\n",
    "#print(features, label)\n",
    "data_numpy = X1.to_numpy()\n",
    "print(data_numpy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "473a2d5e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDED\n",
    "\n",
    "# generate neighborhood\n",
    "from neighborhood import naive_neighborhood_instance\n",
    "\n",
    "# parameters\n",
    "N = 5000\n",
    "C = 15\n",
    "\n",
    "neigh = naive_neighborhood_instance(features.to_numpy(), C, N, np.transpose(data_numpy), 42)\n",
    "#print(neigh)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cd0ff27",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train a decision tree (ML classifier)\n",
    "clf1 = DecisionTreeClassifier(max_depth=3)\n",
    "clf1.fit(X1, y1)\n",
    "#clf2 = DecisionTreeClassifier(max_depth=3)\n",
    "#clf2.fit(X2, y2)\n",
    "\n",
    "# train a random forest, XGB classifier and neural net\n",
    "xgb = XGBClassifier(random_state = 0)\n",
    "xgb.fit(X1, y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f385b759",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADDED\n",
    "\n",
    "# label\n",
    "neigh_label = clf1.predict(neigh)\n",
    "neigh_label_xgb = xgb.predict(neigh)\n",
    "\n",
    "# split neigh\n",
    "neigh_train, neigh_test, neigh_label_train, neigh_label_test = train_test_split(neigh, neigh_label_xgb, test_size=0.3, random_state=42)\n",
    "\n",
    "# ratio to check class balance\n",
    "print(\"orig predictor\", sum(neigh_label), N)\n",
    "print(sum(neigh_label_xgb), N)\n",
    "\n",
    "# learn base model (DT) on full neighborhood\n",
    "neigh_clf = DecisionTreeClassifier(max_depth=3)\n",
    "neigh_clf.fit(neigh, neigh_label)\n",
    "neigh_clf_xgb = DecisionTreeClassifier(max_depth=3)\n",
    "neigh_clf_xgb.fit(neigh, neigh_label_xgb)\n",
    "\n",
    "neigh_clf_train_xgb = DecisionTreeClassifier(max_depth=3)\n",
    "neigh_clf_train_xgb.fit(neigh_train, neigh_label_train)\n",
    "\n",
    "# train = test QUICK AND DIRTY : print(neigh_clf.score(neigh, neigh_label), neigh_clf_xgb.score(neigh, neigh_label_xgb))\n",
    "\n",
    "# FIDELITY\n",
    "print(neigh_clf_train_xgb.score(neigh_test, neigh_label_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "74276ce0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# visualize the decision tree\n",
    "dot_data = tree.export_graphviz(neigh_clf_xgb, out_file=None, \n",
    "                                feature_names=encoded_pred_atts, # attributes names\n",
    "                                class_names=df_code.decode[target], # class labels\n",
    "                                filled=True, rounded=True)  \n",
    "graph = pydotplus.graph_from_dot_data(dot_data)  \n",
    "Image(graph.create_png())"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "f760dc7a",
   "metadata": {},
   "source": [
    "### Decision tree paths to CLP rules "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1f0889f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Model2CLP\n",
    "r = reasonx.ReasonX(pred_atts, target, df_code)\n",
    "r.model(neigh_clf_train_xgb)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be564d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why was my credit application rejected?\n",
    "# ANSWER 1\n",
    "\n",
    "# factual rule on an instance\n",
    "r.instance('F', features=X1.iloc[0:1], label=y1.iloc[0])\n",
    "r.solveopt(verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce57c880",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Why was my credit application rejected?\n",
    "# ANSWER 2\n",
    "\n",
    "# counter-factual rules with min conf\n",
    "print(\"iter 0\")\n",
    "r.instance('CE', label=1-y1.iloc[0], minconf=0.9)\n",
    "r.solveopt(verbose=2)\n",
    "print(\"iter 1\")\n",
    "r.instance('CE', label=1-y1.iloc[0], minconf=0.8)\n",
    "r.solveopt(verbose=2)\n",
    "print(\"iter 2\")\n",
    "r.instance('CE', label=1-y1.iloc[0], minconf=0.7)\n",
    "r.solveopt(verbose=2)\n",
    "print(\"iter 3\")\n",
    "r.instance('CE', label=1-y1.iloc[0], minconf=0.6)\n",
    "r.solveopt(verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f517d2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# ADD BGK\n",
    "# on the age (CF.age = F.age)\n",
    "\n",
    "r.constraint(\"CE.age = F.age\")\n",
    "r.solveopt(verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eff18d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CLOSEST CE\n",
    "\n",
    "r.solveopt(minimize='l1norm(F, CE)', project=['CE'], verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "001346f0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# UNDER-SPECIFIED INFORMATION\n",
    "\n",
    "r.retract(\"F.age=19.0\")\n",
    "r.constraint(\"F.age<=19.0\")\n",
    "r.solveopt(minimize='l1norm(F, CE)', project=[\"CE\", \"F.age\"], verbose = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05404f8e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# CHECK data point\n",
    "\n",
    "X1.iloc[0:1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0c5e235",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  },
  "vscode": {
   "interpreter": {
    "hash": "b499ec7e8aa7b7e88f0bd998e16fdde8e9da12a90931e877dcf32e2f51eecc29"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
